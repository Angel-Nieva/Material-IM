print(sospechosos4)
# Finalmente, los casos no deberían desviarse significativamente
# de los límites recomendados para la razón de covarianza:
# CVRi > 1 + [3(k + 1)/n]
# CVRi < 1 – [3(k + 1)/n]
CVRi.lower <- 1 - 3 * apalancamiento.promedio
CVRi.upper <- 1 + 3 * apalancamiento.promedio
sospechosos5 <- which(eval.rls[["covariance.ratios"]] < CVRi.lower |
eval.rls[["covariance.ratios"]] > CVRi.upper)
cat("- Residuos con razón de covarianza fuera de rango ([", CVRi.lower, ", ",
CVRi.upper, "]): ", sep = "")
print(sospechosos5)
sospechosos <- c(sospechosos1, sospechosos2, sospechosos3, sospechosos4,
sospechosos5)
sospechosos <- sort(unique(sospechosos))
cat("\nResumen de observaciones sospechosas:\n")
cat("Intervalo razón de covarianza: [", CVRi.lower, "; ",
CVRi.upper, "]\n\n", sep = "")
print(round(eval.rls[sospechosos,
c("cooks.distance", "leverage", "covariance.ratios")],
3))
ncol(modelo)
modelo
summary(modelo)
nrow(modelo)
eval.rls <- data.frame(predicted.probabilities = fitted(modelo[["finalModel"]]))
eval.rls[["standardized.residuals"]] <- rstandard(modelo[["finalModel"]])
eval.rls[["studentized.residuals"]] <-rstudent(modelo[["finalModel"]])
eval.rls[["cooks.distance"]] <- cooks.distance(modelo[["finalModel"]])
eval.rls[["dfbeta"]] <- dfbeta(modelo[["finalModel"]])
eval.rls[["dffit"]] <- dffits(modelo[["finalModel"]])
eval.rls[["leverage"]] <- hatvalues(modelo[["finalModel"]])
eval.rls[["covariance.ratios"]] <- covratio(modelo[["finalModel"]])
cat("Influencia de los casos:\n")
# 95% de los residuos estandarizados deberían estar entre −1.96 y +1.96, y 99%
# entre -2.58 y +2.58.
sospechosos1 <- which(abs(eval.rls[["standardized.residuals"]]) > 1.96)
cat("- Residuos estandarizados fuera del 95% esperado: ")
print(sospechosos1)
# Observaciones con distancia de Cook mayor a uno.
sospechosos2 <- which(eval.rls[["cooks.distance"]] > 1)
cat("- Residuos con distancia de Cook mayor que 1: ")
print(sospechosos2)
apalancamiento.promedio <- (ncol(muestra_hombres) + 1/ nrow(muestra_hombres))
sospechosos3 <- which(eval.rls[["leverage"]] > 2 * apalancamiento.promedio)
cat("- Residuos con apalancamiento fuera de rango (promedio = ",
apalancamiento.promedio, "): ", sep = "")
print(sospechosos3)
ncol(muestra_hombres)
nrow(muestra_hombres)
apalancamiento.promedio
sospechosos3 <- which(eval.rls[["leverage"]] > 2 * apalancamiento.promedio)
cat("- Residuos con apalancamiento fuera de rango (promedio = ",
apalancamiento.promedio, "): ", sep = "")
print(sospechosos3)
# DFBeta debería ser < 1.
sospechosos4 <- which(apply(eval.rls[["dfbeta"]] >= 1, 1, any))
names(sospechosos4) <- NULL
cat("- Residuos con DFBeta mayor que 1: ")
print(sospechosos4)
# Finalmente, los casos no deberían desviarse significativamente
# de los límites recomendados para la razón de covarianza:
# CVRi > 1 + [3(k + 1)/n]
# CVRi < 1 – [3(k + 1)/n]
CVRi.lower <- 1 - 3 * apalancamiento.promedio
CVRi.upper <- 1 + 3 * apalancamiento.promedio
sospechosos5 <- which(eval.rls[["covariance.ratios"]] < CVRi.lower |
eval.rls[["covariance.ratios"]] > CVRi.upper)
cat("- Residuos con razón de covarianza fuera de rango ([", CVRi.lower, ", ",
CVRi.upper, "]): ", sep = "")
print(sospechosos5)
sospechosos <- c(sospechosos1, sospechosos2, sospechosos3, sospechosos4,
sospechosos5)
sospechosos <- sort(unique(sospechosos))
cat("\nResumen de observaciones sospechosas:\n")
print(round(eval.rls[sospechosos,
c("cooks.distance", "leverage", "covariance.ratios")],
3))
CVRi.lower
apalancamiento.promedio
apalancamiento.promedio <- (ncol(muestra_hombres) / nrow(muestra_hombres))
sospechosos3 <- which(eval.rls[["leverage"]] > 2 * apalancamiento.promedio)
cat("- Residuos con apalancamiento fuera de rango (promedio = ",
apalancamiento.promedio, "): ", sep = "")
print(sospechosos3)
# DFBeta debería ser < 1.
sospechosos4 <- which(apply(eval.rls[["dfbeta"]] >= 1, 1, any))
names(sospechosos4) <- NULL
cat("- Residuos con DFBeta mayor que 1: ")
print(sospechosos4)
# Finalmente, los casos no deberían desviarse significativamente
# de los límites recomendados para la razón de covarianza:
# CVRi > 1 + [3(k + 1)/n]
# CVRi < 1 – [3(k + 1)/n]
CVRi.lower <- 1 - 3 * apalancamiento.promedio
CVRi.upper <- 1 + 3 * apalancamiento.promedio
sospechosos5 <- which(eval.rls[["covariance.ratios"]] < CVRi.lower |
eval.rls[["covariance.ratios"]] > CVRi.upper)
cat("- Residuos con razón de covarianza fuera de rango ([", CVRi.lower, ", ",
CVRi.upper, "]): ", sep = "")
print(sospechosos5)
sospechosos <- c(sospechosos1, sospechosos2, sospechosos3, sospechosos4,
sospechosos5)
sospechosos <- sort(unique(sospechosos))
cat("\nResumen de observaciones sospechosas:\n")
cat("Intervalo de razón covarianza: [", )
print(round(eval.rls[sospechosos,
c("cooks.distance", "leverage", "covariance.ratios")],
3))
cat("- Residuos con razón de covarianza fuera de rango ([", CVRi.lower, ", ",
CVRi.upper, "]): ", sep = "")
print(sospechosos5)
sospechosos <- c(sospechosos1, sospechosos2, sospechosos3, sospechosos4,
sospechosos5)
sospechosos <- sort(unique(sospechosos))
cat("\nResumen de observaciones sospechosas:\n")
print(round(eval.rls[sospechosos,
c("cooks.distance", "leverage", "covariance.ratios")],
3))
sospechosos1 <- which(abs(eval.rls[["standardized.residuals"]]) > 1.96)
cat("- Residuos estandarizados fuera del 95% esperado: ")
print(sospechosos1)
sospechosos2 <- which(eval.rls[["cooks.distance"]] > 1)
cat("- Residuos con distancia de Cook mayor que 1: ")
print(sospechosos2)
apalancamiento.promedio <- (ncol(muestra_hombres) / nrow(muestra_hombres))
sospechosos3 <- which(eval.rls[["leverage"]] > 2 * apalancamiento.promedio)
cat("- Residuos con apalancamiento fuera de rango (promedio = ",
apalancamiento.promedio, "): ", sep = "")
print(sospechosos3)
sospechosos4 <- which(apply(eval.rls[["dfbeta"]] >= 1, 1, any))
names(sospechosos4) <- NULL
cat("- Residuos con DFBeta mayor que 1: ")
print(sospechosos4)
CVRi.lower <- 1 - 3 * apalancamiento.promedio
CVRi.upper <- 1 + 3 * apalancamiento.promedio
sospechosos5 <- which(eval.rls[["covariance.ratios"]] < CVRi.lower |
eval.rls[["covariance.ratios"]] > CVRi.upper)
cat("- Residuos con razón de covarianza fuera de rango ([", CVRi.lower, ", ",
CVRi.upper, "]): ", sep = "")
print(sospechosos5)
sospechosos <- c(sospechosos1, sospechosos2, sospechosos3, sospechosos4,
sospechosos5)
sospechosos <- sort(unique(sospechosos))
cat("\nResumen de observaciones sospechosas:\n")
print(round(eval.rls[sospechosos,
c("cooks.distance", "leverage", "covariance.ratios")],
3))
print(summary(rls))
print(summary(rls))
print(summary(modelo))
library(tidyverse)
# Fijar semilla.
set.seed(1111)
# Cargar datos.
#datos <- read.csv2("EP13 Datos.csv")
basename <- "EP13 Datos.csv"
file <- file.path("C:/Users/Dell PC/Desktop/IME-2022/Actividades/act13",basename)
datos <- read.csv2(file = file)
# Obtener muestra.
datos <- datos %>% filter(Gender == 1)
datos[["Gender"]] <- NULL
datos <- sample_n(datos, 50, replace = FALSE)
# Separar variable de respuesta.
respuesta <- datos[["Knees.diameter"]]
datos[["Knees.diameter"]] <- NULL
# Seleccionar 8 variables predictoras al azar y construir matriz de datos para
# RLM.
variables <- colnames(datos)
predictores <- sample(variables, 8, replace = FALSE)
cat("Predictores seleccionados al azar:\n")
print(predictores)
datos.rlm <- datos %>% select(predictores)
datos.rlm <- cbind(respuesta, datos.rlm)
# Los predictores seleccionados al azar para el modelo de regresión lineal
# múltiple son: Knee.Girth, Bicep.Girth, Ankles.diameter, Chest.depth,
# Shoulder.Girth, Navel.Girth, Hip.Girth, Biiliac.diameter.
# Evaluar correlación de las variables restantes con la respuesta.
datos <- datos %>% select(!predictores)
cat("\nMatriz de correlación:\n")
correlacion <- cor(datos, y = respuesta)
cat("\nMatriz de correlación:\n")
print(correlacion)
# El mejor predictor para un modelo de RLS es aquella variable con mayor
# correlación (directa o inversa) con la variable de respuesta. Armar conjunto
# de datos para RLS.
mejor <- which(correlacion == max(abs(correlacion)))
predictor <- rownames(correlacion)[mejor]
datos.rls <- datos %>% select(mejor)
datos.rls <- cbind(respuesta, datos.rls)
cat("\nVariable más correlacionada con el diámetro de las rodillas:",
predictor, "\n\n\n\n")
################################################################################
# RLS
################################################################################
cat("-----------------------------------------------------------------------\n")
cat("Regresión lineal simple\n")
cat("-----------------------------------------------------------------------\n")
# Ajustar modelo de regresión lineal simple usando validación cruzada de 10
# pliegues.
library(caret)
rls <- train (respuesta ~ Thigh.Girth, data = datos.rls, method = "lm",
trControl = trainControl(method = "cv", number = 10))
cat("\nModelo de regresión lineal simple\n")
print(summary(rls))
# Evaluar modelo.
# Obtener residuos y estadísticas de influencia de los casos.
eval.rls <- data.frame(predicted.probabilities = fitted(rls[["finalModel"]]))
eval.rls[["standardized.residuals"]] <- rstandard(rls[["finalModel"]])
eval.rls[["studentized.residuals"]] <-rstudent(rls[["finalModel"]])
eval.rls[["cooks.distance"]] <- cooks.distance(rls[["finalModel"]])
eval.rls[["dfbeta"]] <- dfbeta(rls[["finalModel"]])
eval.rls[["dffit"]] <- dffits(rls[["finalModel"]])
eval.rls[["leverage"]] <- hatvalues(rls[["finalModel"]])
eval.rls[["covariance.ratios"]] <- covratio(rls[["finalModel"]])
cat("Influencia de los casos:\n")
# 95% de los residuos estandarizados deberían estar entre −1.96 y +1.96, y 99%
# entre -2.58 y +2.58.
sospechosos1 <- which(abs(eval.rls[["standardized.residuals"]]) > 1.96)
cat("- Residuos estandarizados fuera del 95% esperado: ")
print(sospechosos1)
# Observaciones con distancia de Cook mayor a uno.
sospechosos2 <- which(eval.rls[["cooks.distance"]] > 1)
cat("- Residuos con distancia de Cook mayor que 1: ")
print(sospechosos2)
# Observaciones con apalancamiento superior al doble del apalancamiento
# promedio: (k + 1)/n.
apalancamiento.promedio <- ncol(datos.rls) / nrow(datos.rls)
sospechosos3 <- which(eval.rls[["leverage"]] > 2 * apalancamiento.promedio)
cat("- Residuos con apalancamiento fuera de rango (promedio = ",
apalancamiento.promedio, "): ", sep = "")
print(sospechosos3)
# DFBeta debería ser < 1.
sospechosos4 <- which(apply(eval.rls[["dfbeta"]] >= 1, 1, any))
names(sospechosos4) <- NULL
cat("- Residuos con DFBeta mayor que 1: ")
print(sospechosos4)
# Finalmente, los casos no deberían desviarse significativamente
# de los límites recomendados para la razón de covarianza:
# CVRi > 1 + [3(k + 1)/n]
# CVRi < 1 – [3(k + 1)/n]
CVRi.lower <- 1 - 3 * apalancamiento.promedio
CVRi.upper <- 1 + 3 * apalancamiento.promedio
sospechosos5 <- which(eval.rls[["covariance.ratios"]] < CVRi.lower |
eval.rls[["covariance.ratios"]] > CVRi.upper)
cat("- Residuos con razón de covarianza fuera de rango ([", CVRi.lower, ", ",
CVRi.upper, "]): ", sep = "")
print(sospechosos5)
sospechosos <- c(sospechosos1, sospechosos2, sospechosos3, sospechosos4,
sospechosos5)
sospechosos <- sort(unique(sospechosos))
cat("\nResumen de observaciones sospechosas:\n")
print(round(eval.rls[sospechosos,
c("cooks.distance", "leverage", "covariance.ratios")],
3))
library(dplyr) # Filter
library(ggpubr)
library(leaps)
library(car) #
library(caret) # train
basename <- "EP13 Datos.csv"
file <- file.path("C:/Users/Dell PC/Desktop/IME-2022/Actividades/act13",basename)
datos <- read.csv2(file = file)
# PRIMER PASO
# Se establece la semilla según el integrante de menor edad en el equipo
# (últimos 4 dígitos de su rut).
semilla <- 0731
set.seed(semilla)
# SEGUNDO PASO
# Seleccionar una muestra de 50 mujeres (si la semilla es numero par)
# o 50 hombres (si la semilla es número impar).
# Hombres
datos_hombres <- filter(datos, Gender == 1)
datos_hombres <- datos_hombres[sample(nrow(datos_hombres), 50, replace = F), ]
datos_hombres["Gender"] <- NULL
# TERCER PASO
# Seleccionar de forma aleatoria ocho posibles variables predictoras.
muestra_hombres <- datos_hombres
# Separar variable de respuesta.
peso <- muestra_hombres["Weight"]
muestra_hombres["Weight"] <- NULL
# Se obtienen las 8 variables
columnas_muestra <- colnames(muestra_hombres)
predictores_aleatorios <- sample(columnas_muestra,8,replace = FALSE)
cat("Predictores seleccionados al azar:\n")
print(predictores_aleatorios)
# CUARTO PASO
# Seleccionar, de las otras variables, una que el equipo considere que podría ser útil
# para predecir la variable Peso, justificando bien esta selección.
# Se almacenan los posibles predictores que pueden ser seleccionados
variables_restantes <- setdiff(columnas_muestra, predictores_aleatorios)
# Se reduce el data.frame con las columnas a utilizar.
muestra_hombres <- muestra_hombres[variables_restantes]
# Se agrega la columna peso a la muestra obtenida.
muestra_hombres <- cbind(muestra_hombres, peso)
# Se utiliza la función add1, la cual evalúa la incorporación de cada nuevo predictor potencial
# a un modelo base y entrega algunas métricas para el efecto que tiene en su incorporación.
# Ajustar un modelo nulo.
nulo <- lm(Weight ~ 1, data = muestra_hombres)
# Ajustar modelo completo.
completo <- lm(Weight ~ ., data = muestra_hombres)
# Evaluar la variable para incorporar
print(add1(nulo, scope = completo))
# Se obtiene que el mejor predictor para incorporar al modelo nulo es Hip.Girth, ya que según la función
# add1, es el predictor que retorna el menor AIC al ser incorporado al modelo.
# Además, con la ayuda de la función cor, podemos ver que la variable predictora con la mayor
# correlación es Hip.Girth (Grosor a la altura de las caderas). Por lo que la variable predictora
# Hip.Girth puede ser útil para predecir la variable peso.
correlaciones <- round(cor(x = muestra_hombres, method = "pearson"), 3)
# QUINTO PASO
# Construir un modelo de regresión lineal simple con el predictor seleccionado en el paso anterior.
# modelo <- lm(Weight ~ Hip.Girth, data = muestra_hombres)
# print(summary(modelo))
# Ajustar modelo de regresión lineal simple usando validación cruzada de 10
# pliegues.
modelo <- train (Weight ~ Hip.Girth, data = muestra_hombres, method = "lm",
trControl = trainControl(method = "cv", number = 10))
cat("\nModelo de regresión lineal simple\n")
print(summary(modelo))
# Se grafica el modelo.
g <- ggscatter(muestra_hombres, x = "Hip.Girth", y = "Weight", color = "blue",
xlab = "Grosor a la altura de las caderas", ylab = "Peso")
print(g)
# SEXTO PASO
# Usando herramientas para la exploración de modelos del entorno R, buscar entre dos y cinco predictores
# de entre las variables seleccionadas al azar en el punto 3, para agregar al modelo de regresión lineal
# simple obtenido en el paso 5.
# Se reduce el data.frame con las columnas a utilizar y se guarda la columna Hip.Girth .
muestra_hombres_2 <- datos_hombres
girth <- muestra_hombres_2["Hip.Girth"]
muestra_hombres_2 <- muestra_hombres_2[predictores_aleatorios]
# Se agrega la columna peso y Hip.Girt
muestra_hombres_2 <- cbind(muestra_hombres_2, peso)
muestra_hombres_2 <- cbind(muestra_hombres_2, girth)
# Se recrea el modelo del paso 5
modelo_2 <- lm(Weight ~ Hip.Girth, data = muestra_hombres_2)
print(summary(modelo_2))
#Se grafica el modelo.
g_2 <- ggscatter(muestra_hombres_2, x = "Hip.Girth", y = "Weight", color = "blue",
xlab = "Grosor a la altura de las caderas", ylab = "Peso")
print(g_2)
# Ajustar modelo completo
completo2 <- lm(Weight ~ ., data=muestra_hombres_2)
# Ajustar modelo con eliminación hacia atrás
backwards <- step(object = completo2, scope = list(lower = modelo_2),
direction = "backward",
trace = 0)
print(summary(backwards))
#AIC(backwards) = 260.6668
# Utilizando eliminación hacia atrás, se agregan 6 predictores al modelo:
# Ankle.Minimum.Girth, Waist.Girth, Chest.Girth, Biiliac.diameter, Age y Elbows.diameter.
# Como nos piden agregar un máximo de 5 predictores al modelo de regresión lineal simple,
# Se estudia la correlación entre estos predictores y la variable respuesta (Weight) para ver
# si existe una relación lineal, en caso contrario, no se agrega al modelo.
correlaciones <- round(cor(x = muestra_hombres_2, method = "pearson"), 3)
# Se puede ver que el predictor Age tiene la menor correlación entre los predictores (0.116), por lo
# que no se agrega al modelo. Finalmente, los predictores para agregar al modelo del paso 5 son:
# Waist.Girth, Chest.Girth, Biiliac.diameter, Age y Elbows.diameter.
modelo_final <- update(modelo_2, . ~ . + Ankle.Minimum.Girth + Waist.Girth + Chest.Girth +
Biiliac.diameter  + Elbows.diameter)
# SÉPTIMO PASO
# Evaluar los modelos y “arreglarlos” en caso de que tengan algún problema con
# las condiciones que deben cumplir.
# Se define un nivel de significación:
alfa <- 0.05
# Se comprueban las condiciones para el primer modelo de RLS:
# Condiciones:
# 1. Los datos deben presentar una relación lineal.
# 2. La distribución de los residuos debe ser cercana a la normal.
# 3. La variabilidad de los puntos en torno a la línea de mínimos cuadrados debe ser aproximadamente
#    constante.
# 4. Las observaciones deben ser independientes entre sí.
# Verificación de condiciones:
# 1) Se puede saber si existe una relación lineal entre la variable predictora (Hip.Girth)
#    y respuesta (Weight) mediante la correlación entre las dos variables.
correlaciones_2 <- round(cor(x = muestra_hombres, method = "pearson"), 3)
cat("\n\n")
# Se obtiene una correlación de 0.892 para Weight~Hip.Girth, lo que significa que existe
# una relación lineal directa relativamente fuerte entre la variable respuesta y predictora.
# 2) Verificar la normalidad de los residuos
print(shapiro.test(modelo$residuals))
# p-value = 0.1424
# Al aplicar la prueba de normalidad de los residuos concluimos que estos siguen una
# distribución cercana a la normal ( p > alfa).
# 3) Graficar los residuos para estudiar la variabilidad de los puntos.
b_1 <- modelo$coefficients[2]
b_0 <- modelo$coefficients[1]
residuos <- muestra_hombres[["Weight"]] - (b_1 * muestra_hombres[["Hip.Girth"]] + b_0)
muestra_hombres <- data.frame(muestra_hombres, residuos)
g_var <- ggscatter(muestra_hombres, x = "Hip.Girth", y = "residuos", color = "blue", fill = "blue",
xlab = "Grosor a la altura de las caderas", ylab = "Residuos")
g_var <- g_var + geom_hline(yintercept = 0, colour = "red")
print(g_var)
# Se puede apreciar en la grafica que la variabilidad de los residuos
# es relativamente constante.
# 4) Las observaciones son independientes entre sí, pues han sido seleccionadas
# de manera aleatoria y corresponden a menos del 10% de la población.
# Por lo tanto, se cumplen todas las condiciones para el primer modelo de RLS.
# Evaluar modelo.
# Obtener residuos y estadísticas de influencia de los casos.
eval.rls <- data.frame(predicted.probabilities = fitted(modelo[["finalModel"]]))
eval.rls[["standardized.residuals"]] <- rstandard(modelo[["finalModel"]])
eval.rls[["studentized.residuals"]] <-rstudent(modelo[["finalModel"]])
eval.rls[["cooks.distance"]] <- cooks.distance(modelo[["finalModel"]])
eval.rls[["dfbeta"]] <- dfbeta(modelo[["finalModel"]])
eval.rls[["dffit"]] <- dffits(modelo[["finalModel"]])
eval.rls[["leverage"]] <- hatvalues(modelo[["finalModel"]])
eval.rls[["covariance.ratios"]] <- covratio(modelo[["finalModel"]])
cat("Influencia de los casos:\n")
# 95% de los residuos estandarizados deberían estar entre −1.96 y +1.96, y 99%
# entre -2.58 y +2.58.
sospechosos1 <- which(abs(eval.rls[["standardized.residuals"]]) > 1.96)
cat("- Residuos estandarizados fuera del 95% esperado: ")
print(sospechosos1)
# Observaciones con distancia de Cook mayor a uno.
sospechosos2 <- which(eval.rls[["cooks.distance"]] > 1)
cat("- Residuos con distancia de Cook mayor que 1: ")
print(sospechosos2)
# Observaciones con apalancamiento superior al doble del apalancamiento
# promedio: (k + 1)/n.
apalancamiento.promedio <- (ncol(muestra_hombres) / nrow(muestra_hombres))
sospechosos3 <- which(eval.rls[["leverage"]] > 2 * apalancamiento.promedio)
cat("- Residuos con apalancamiento fuera de rango (promedio = ",
apalancamiento.promedio, "): ", sep = "")
print(sospechosos3)
# DFBeta debería ser < 1.
sospechosos4 <- which(apply(eval.rls[["dfbeta"]] >= 1, 1, any))
names(sospechosos4) <- NULL
cat("- Residuos con DFBeta mayor que 1: ")
print(sospechosos4)
# Finalmente, los casos no deberían desviarse significativamente
# de los límites recomendados para la razón de covarianza:
# CVRi > 1 + [3(k + 1)/n]
# CVRi < 1 – [3(k + 1)/n]
CVRi.lower <- 1 - 3 * apalancamiento.promedio
CVRi.upper <- 1 + 3 * apalancamiento.promedio
sospechosos5 <- which(eval.rls[["covariance.ratios"]] < CVRi.lower |
eval.rls[["covariance.ratios"]] > CVRi.upper)
cat("- Residuos con razón de covarianza fuera de rango ([", CVRi.lower, ", ",
CVRi.upper, "]): ", sep = "")
print(sospechosos5)
sospechosos <- c(sospechosos1, sospechosos2, sospechosos3, sospechosos4,
sospechosos5)
sospechosos <- sort(unique(sospechosos))
cat("\nResumen de observaciones sospechosas:\n")
print(round(eval.rls[sospechosos,
c("cooks.distance", "leverage", "covariance.ratios")],
3))
summary(modelo)
library(tidyverse)
library(caret)
library(pROC)
library(leaps)
library(car)
library(tidyverse)
library(caret)
library(pROC)
library(leaps)
library(car)
# Fijar semilla.
set.seed(1111)
# Cargar datos.
#datos <- read.csv2("EP13 Datos.csv")
basename <- "EP13 Datos.csv"
file <- file.path("C:/Users/Dell PC/Desktop/IME-2022/Actividades/act13",basename)
datos <- read.csv2(file = file)
# Generar nuevas columnas.
datos[["IMC"]] <- datos[["Weight"]] / ((datos[["Height"]] / 100) ** 2)
datos[["EN"]] <- rep("Sobrepeso", length(datos[["IMC"]]))
datos[["EN"]][datos[["IMC"]] < 25] <- "No sobrepeso"
datos[["EN"]] <- factor(datos[["EN"]])
# Seleccionar muestra.
sobrepeso <- datos %>% filter(EN == "Sobrepeso")
sobrepeso <- sample_n(sobrepeso, 50, replace = FALSE)
normal <- datos %>% filter(EN != "Sobrepeso")
normal <- sample_n(normal, 50, replace = FALSE)
muestra <- rbind(sobrepeso, normal)
rm(datos, normal, sobrepeso)
################################################################################
# Regresión lineal múltiple para la variable peso.
################################################################################
# Descartar columnas inútiles
datos.peso <- muestra %>% select(-c(IMC, EN))
# Seleccionar predictores usando el método de todos los subconjuntos.
preliminar <- regsubsets(Weight ~ ., data = datos.peso, nbest = 1, nvmax = 8,
method = "exhaustive")
plot(preliminar)
# El modelo con menor BIC con entre 2 y 8 predictores incluye únicamente el
# diámetro del pecho y el diámetro de las caderas.
datos.peso <- datos.peso %>% select(Weight, Chest.Girth, Hip.Girth)
# Ajustar modelo usando bootstrapping con 2999 remuestreos.
modelo.peso <- train(Weight ~ ., data = datos.peso, method = "lm",
trControl = trainControl(method = "boot", number = 2999))
print(summary(modelo.peso))
datos.imc <- muestra %>% select(-c(Weight, Height, EN))
# Separar variable de respuesta de los predictores.
IMC <- datos.imc[["IMC"]]
datos.imc[["IMC"]] <- NULL
# Ajustamos el modelo usando R^2 para seleccionar predictores y cinco
# repeticiones de validación cruzada de cinco pliegues.
# Caret implementa la regresión escalonada hacia atrás (bajo el nombre de
# Recursive Feature Elimination) mediante la función rfe().
# Se pueden definir alternativas de control que guíen la búsqueda, incluyendo
# funciones wrapper para el tipo de modelo. El paquete caret proporciona la
# función wrapper lmFuncs para modelos de regresión lineal.
control <- rfeControl(functions = lmFuncs, method="repeatedcv",
number=5, repeats=5, verbose = FALSE)
modelo.imc <- rfe(datos.imc, IMC, rfeControl = control, sizes = 10:20,
metric = "Rsquared")
print(modelo.imc)
print(modelo.imc[["optVariables"]])
print(ggplot(modelo.imc))
